{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Load .env file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "_ = load_dotenv(override=True)\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `ChatModels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, AIMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quantum mechanics is the branch of physics that describes the behavior of matter and energy at the smallest scales, where particles exhibit wave-particle duality, superposition, and entanglement, challenging classical intuitions about reality.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatOpenAI Model\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY)  \n",
    "\n",
    "# Invoking\n",
    "output = llm.invoke('Explain quantum mechanics in one sentence.', model='gpt-4o-mini', temperature=0.1)\n",
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'الميكانيكا الكمية هي النظرية التي تصف سلوك الجسيمات الصغيرة مثل الذرات والإلكترونات بطريقة تعتمد على الاحتمالات والموجات والتفاعلات الكمومية.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Chat Completions API Messages: System, Assistant and Human\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in Arabic.'),\n",
    "    HumanMessage(content='Explain quantum mechanics in one sentence.')\n",
    "]\n",
    "\n",
    "# Invoking\n",
    "output = llm.invoke(messages)\n",
    "output.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `Caching LLM Response`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain_openai import OpenAI\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `1. In-Memory Chache`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching in Memory\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time is 1.3673558235168457\n",
      "\n",
      "\n",
      "Why did the orange stop rolling?\n",
      "\n",
      "Because it ran out of juice!\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "start = time.time()\n",
    "\n",
    "llm = OpenAI(model_name='gpt-3.5-turbo-instruct')\n",
    "\n",
    "prompt = 'Tell a me a joke that a toddler can understand in Arabic'\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(f'Time is {time.time() - start}')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time is 0.0010025501251220703\n",
      "\n",
      "\n",
      "Why did the orange stop rolling?\n",
      "\n",
      "Because it ran out of juice!\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "start = time.time()\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(f'Time is {time.time() - start}')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `2. SQLite Caching`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching in SQLite DB\n",
    "set_llm_cache(SQLiteCache(database_path='../assets/langchain.db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time is 1.7940633296966553\n",
      "\n",
      "\n",
      "ما هو الفرق بين القط والكلب؟\n",
      "القط يقول \"ماو\" والكلب يقول \"وف وف\"، ولكن الإبل تقول \"حمار\"!\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "start = time.time()\n",
    "\n",
    "prompt = 'Tell a me a joke that a toddler can understand in Arabic.'\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(f'Time is {time.time() - start}')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time is 1.3386597633361816\n",
      "\n",
      "\n",
      "Why was the math book sad? Because it had too many problems.\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "start = time.time()\n",
    "\n",
    "prompt = 'Tell a me a joke that a toddler can understand.'\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(f'Time is {time.time() - start}')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `LLM Streaming`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Verse 1:\\nIn the dead of night, a raven takes flight\\nGuided by the pale moonlight\\nIts black wings against the dark sky\\nA haunting presence as it flies\\n\\nChorus:\\nMoon and raven, dancing in the night\\nA symphony of darkness, a beautiful sight\\nTheir spirits intertwined, forever entwined\\nIn the shadows of the night, they both will find\\n\\nVerse 2:\\nThe moon watches over, a silent guardian\\nAs the raven caws its ominous hymn\\nTogether they rule the night sky\\nA mystical duo, never asking why\\n\\nChorus:\\nMoon and raven, dancing in the night\\nA symphony of darkness, a beautiful sight\\nTheir spirits intertwined, forever entwined\\nIn the shadows of the night, they both will find\\n\\nBridge:\\nThe moon whispers secrets to the raven's ear\\nAs they soar through the darkness, without fear\\nTheir bond unbreakable, their connection strong\\nIn the night they belong, where they truly belong\\n\\nChorus:\\nMoon and raven, dancing in the night\\nA symphony of darkness, a beautiful sight\\nTheir spirits intertwined, forever entwined\\nIn the shadows of the night, they both will find\\n\\nOutro:\\nMoon and raven, a mysterious pair\\nIn the darkness, they'll always be there\\nWatching over us, from up above\\nMoon and raven, the guardians of love.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY)\n",
    "prompt = 'Write a rock song about the Moon and a Raven.'\n",
    "llm.invoke(prompt).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verse 1:\n",
      "The moon hangs high in the night sky\n",
      "A raven flies, casting shadows below\n",
      "Their dance in the darkness, a sight to behold\n",
      "Mysteries untold, secrets they both know\n",
      "\n",
      "Chorus:\n",
      "Moon and raven, spirits of the night\n",
      "Guiding us through the darkness, shining so bright\n",
      "Together they roam, in the midnight hour\n",
      "A bond unbroken, a timeless power\n",
      "\n",
      "Verse 2:\n",
      "The moon's silver light, a beacon in the dark\n",
      "The raven's call, a haunting melody\n",
      "They navigate the shadows, with grace and ease\n",
      "A silent partnership, a symphony\n",
      "\n",
      "Chorus:\n",
      "Moon and raven, spirits of the night\n",
      "Guiding us through the darkness, shining so bright\n",
      "Together they roam, in the midnight hour\n",
      "A bond unbroken, a timeless power\n",
      "\n",
      "Bridge:\n",
      "In the still of the night, they watch over us\n",
      "Silent guardians, in the shadows they trust\n",
      "Their presence a comfort, a source of strength\n",
      "In their embrace, we find peace at length\n",
      "\n",
      "Chorus:\n",
      "Moon and raven, spirits of the night\n",
      "Guiding us through the darkness, shining so bright\n",
      "Together they roam, in the midnight hour\n",
      "A bond unbroken, a timeless power\n",
      "\n",
      "Outro:\n",
      "As the night fades into day\n",
      "The moon and raven slowly drift away\n",
      "But their memory lingers, in our hearts they'll stay\n",
      "Moon and raven, forever in our souls they'll play."
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(prompt):\n",
    "    print(chunk.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `PromptTemplate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an experienced Data Scientist.\n",
      "Write a few sentences about the following concepts machine learning in arabic.\n",
      "\n",
      "تعلم الآلة هو فرع من فروع الذكاء الاصطناعي يركز على تطوير خوارزميات ونماذج تمكن الأنظمة من التعلم من البيانات وتحسين أدائها بمرور الوقت دون الحاجة إلى برمجة صريحة. يعتمد تعلم الآلة على تحليل البيانات واستخراج الأنماط منها، مما يسمح للأنظمة باتخاذ قرارات مستنيرة أو إجراء تنبؤات. تشمل تطبيقات تعلم الآلة مجالات متعددة مثل الرؤية الحاسوبية، معالجة اللغة الطبيعية، والتوصيات الشخصية.\n"
     ]
    }
   ],
   "source": [
    "# Define a template for the prompt\n",
    "template = '''You are an experienced Data Scientist.\n",
    "Write a few sentences about the following concepts {concept} in {language}.'''\n",
    "\n",
    "# Create a PromptTemplate object from the template\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "# Fill in the variable: concept and language\n",
    "prompt = prompt_template.format(concept='machine learning', language='arabic')\n",
    "print(prompt)   # Here is the updated prompt of yours\n",
    "\n",
    "print()\n",
    "\n",
    "# Model\n",
    "llm = ChatOpenAI(model_name='gpt-4o-mini', temperature=0)\n",
    "output = llm.invoke(prompt)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `ChatPromptTemplates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You MUST respond only in the JSON format, and make \",\" thousands separators.'), HumanMessage(content='Top 5 countries in World by population.')]\n"
     ]
    }
   ],
   "source": [
    "# Create a chat template with system and human messages\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content='You MUST respond only in the JSON format, and make \",\" thousands separators.'),\n",
    "        HumanMessagePromptTemplate.from_template('Top {n} countries in {area} by population.')\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fill in the specific values for n and area\n",
    "messages = chat_template.format_messages(n='5', area='World')\n",
    "print(messages)  # Outputs the formatted chat messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"top_countries_by_population\": [\n",
      "    {\n",
      "      \"country\": \"China\",\n",
      "      \"population\": 1,412,600,000\n",
      "    },\n",
      "    {\n",
      "      \"country\": \"India\",\n",
      "      \"population\": 1,408,600,000\n",
      "    },\n",
      "    {\n",
      "      \"country\": \"United States\",\n",
      "      \"population\": 333,300,000\n",
      "    },\n",
      "    {\n",
      "      \"country\": \"Indonesia\",\n",
      "      \"population\": 276,400,000\n",
      "    },\n",
      "    {\n",
      "      \"country\": \"Pakistan\",\n",
      "      \"population\": 240,500,000\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, model='gpt-4o-mini', temperature=0)\n",
    "output = llm.invoke(messages)\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Chains`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `1. Simple Chains`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\AppData\\Local\\Temp\\ipykernel_65160\\1912916634.py:10: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  chain = LLMChain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an experience Data Scientist.\n",
      "Write a few sentences about the following concept machine learning in Arabic.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'concept': 'machine learning',\n",
       " 'language': 'Arabic',\n",
       " 'text': 'تعلم الآلة هو فرع من فروع الذكاء الاصطناعي يركز على تطوير خوارزميات ونماذج تمكن الحواسيب من التعلم من البيانات وإجراء التنبؤات أو اتخاذ القرارات بناءً على هذه البيانات. يعتمد تعلم الآلة على تحليل الأنماط واستخراج المعرفة من كميات كبيرة من المعلومات، مما يساعد في تحسين الأداء بمرور الوقت دون الحاجة إلى برمجة محددة. يُستخدم تعلم الآلة في العديد من التطبيقات، مثل التعرف على الصور، معالجة اللغة الطبيعية، وتوصيات المنتجات.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "llm = ChatOpenAI(api_key=OPENAI_API_KEY, model=\"gpt-4o-mini\")\n",
    "\n",
    "# Template\n",
    "template = '''You are an experience Data Scientist.\n",
    "Write a few sentences about the following concept {concept} in {language}.'''\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "# Simple Chains\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Invoke the chain once\n",
    "output = chain.invoke({'concept': 'machine learning', 'language': 'Arabic'})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat is the capital of Egypt?. List the top 3 places to visit in that city. Use bullet points\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The capital of Egypt is Cairo. Here are the top three places to visit in Cairo:\n",
      "\n",
      "- **The Pyramids of Giza**: One of the Seven Wonders of the Ancient World, this iconic site features the Great Pyramid of Khufu, the Sphinx, and other ancient tombs.\n",
      "\n",
      "- **The Egyptian Museum**: Home to an extensive collection of ancient Egyptian antiquities, including the treasures of Tutankhamun and artifacts spanning thousands of years of history.\n",
      "\n",
      "- **Islamic Cairo**: A historic area filled with stunning mosques, markets, and ancient architecture, including notable sites such as the Mosque of Muhammad Ali and the Al-Azhar Mosque.\n"
     ]
    }
   ],
   "source": [
    "template = 'What is the capital of {country}?. List the top 3 places to visit in that city. Use bullet points'\n",
    "prompt_template = PromptTemplate.from_template(template=template)\n",
    "\n",
    "# Initialize an LLMChain with the ChatOpenAI model and the prompt template\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Take the name of Country from user\n",
    "country = input('Enter Country: ')\n",
    "\n",
    "# Invoke the chain with specific virus and language values\n",
    "output = chain.invoke(country)\n",
    "print(output['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Sequential Chains`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mCertainly! Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables. In its simplest form (simple linear regression), we model the relationship between a single independent variable \\(X\\) and a dependent variable \\(Y\\) using the equation:\n",
      "\n",
      "\\[ Y = b_0 + b_1X + \\epsilon \\]\n",
      "\n",
      "Where:\n",
      "- \\(Y\\) is the dependent variable.\n",
      "- \\(X\\) is the independent variable.\n",
      "- \\(b_0\\) is the y-intercept.\n",
      "- \\(b_1\\) is the slope of the line (the coefficient for \\(X\\)).\n",
      "- \\(\\epsilon\\) is the error term.\n",
      "\n",
      "Here's a Python function that implements simple linear regression using the least squares method:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "def linear_regression(X, Y):\n",
      "    \"\"\"\n",
      "    Perform simple linear regression on the given data.\n",
      "\n",
      "    Parameters:\n",
      "    X (array-like): The independent variable (input).\n",
      "    Y (array-like): The dependent variable (output).\n",
      "\n",
      "    Returns:\n",
      "    b0 (float): The y-intercept of the regression line.\n",
      "    b1 (float): The slope of the regression line.\n",
      "    \"\"\"\n",
      "    # Convert X and Y to numpy arrays\n",
      "    X = np.array(X)\n",
      "    Y = np.array(Y)\n",
      "\n",
      "    # Calculate the means of X and Y\n",
      "    X_mean = np.mean(X)\n",
      "    Y_mean = np.mean(Y)\n",
      "\n",
      "    # Calculate the slope (b1)\n",
      "    numerator = np.sum((X - X_mean) * (Y - Y_mean))\n",
      "    denominator = np.sum((X - X_mean) ** 2)\n",
      "    \n",
      "    b1 = numerator / denominator\n",
      "\n",
      "    # Calculate the y-intercept (b0)\n",
      "    b0 = Y_mean - b1 * X_mean\n",
      "\n",
      "    return b0, b1\n",
      "\n",
      "# Example usage:\n",
      "if __name__ == \"__main__\":\n",
      "    # Sample data\n",
      "    X = [1, 2, 3, 4, 5]\n",
      "    Y = [2, 3, 5, 7, 11]\n",
      "\n",
      "    b0, b1 = linear_regression(X, Y)\n",
      "    print(f\"Y-intercept (b0): {b0}\")\n",
      "    print(f\"Slope (b1): {b1}\")\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Input Parameters**: The function takes two inputs: `X` (the independent variable) and `Y` (the dependent variable).\n",
      "2. **Mean Calculation**: It calculates the mean of `X` and `Y`.\n",
      "3. **Slope Calculation**: The slope \\(b_1\\) is calculated using the formula for the least squares solution.\n",
      "4. **Intercept Calculation**: The y-intercept \\(b_0\\) is calculated using the means of `X` and `Y`.\n",
      "5. **Return Values**: The function returns the y-intercept and the slope.\n",
      "\n",
      "### Example Usage:\n",
      "The example at the bottom demonstrates how to call the `linear_regression` function with sample data and print the results. You can replace the `X` and `Y` lists with your own data to perform regression analysis.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mSure! Let's go through the provided Python function for **Simple Linear Regression** in detail. Simple linear regression is widely used in statistics and machine learning to assess the relationship between two continuous variables: the dependent variable (often denoted as \\(Y\\)) and the independent variable (denoted as \\(X\\)). \n",
      "\n",
      "### Breakdown of the Function\n",
      "\n",
      "#### Function Definition and Parameters\n",
      "\n",
      "The function `linear_regression(X, Y)` performs simple linear regression on the datasets provided as parameters. \n",
      "\n",
      "**Parameters**:\n",
      "- `X` (array-like): This is the independent variable, or the input data. It represents values upon which predictions about \\(Y\\) (the dependent variable) are made.\n",
      "- `Y` (array-like): This is the dependent variable, or the target endpoint. It denotes outcomes that depend on the values of \\(X\\).\n",
      "\n",
      "#### Core Steps in the Function\n",
      "\n",
      "1. **Import the NumPy Library**: \n",
      "   ```python\n",
      "   import numpy as np\n",
      "   ```\n",
      "   NumPy is always imported for handling numerical operations, particularly for operations involving arrays.\n",
      "\n",
      "   \n",
      "2. **Convert Input Data to Arrays**:\n",
      "   ```python\n",
      "   X = np.array(X)\n",
      "   Y = np.array(Y)\n",
      "   ```\n",
      "   Here, we convert both `X` and `Y` into NumPy arrays. This is important because NumPy provides highly optimized operations and functionalities that allow for efficient calculations on these arrays.\n",
      "\n",
      "3. **Calculate Means of X and Y**:\n",
      "    ```python\n",
      "    X_mean = np.mean(X)\n",
      "    Y_mean = np.mean(Y)\n",
      "    ```\n",
      "   The means (average) of the independent variable `X` and the dependent variable `Y` are computed using NumPy's mean function. \n",
      "\n",
      "   \n",
      "4. **Calculate the Slope (b1)**:\n",
      "   ```python\n",
      "   numerator = np.sum((X - X_mean) * (Y - Y_mean))\n",
      "   denominator = np.sum((X - X_mean) ** 2)\n",
      "   \n",
      "   b1 = numerator / denominator\n",
      "   ```\n",
      "   - The **numerator** computes the summed product of deviations from the mean for both choices, \\( (X-X_{mean}) \\) and \\( (Y-Y_{mean}) \\).\n",
      "   - The **denominator** computes the summed square of the deviations for `X`.\n",
      "   - The slope \\( b_1 \\) is calculated through the formula:\n",
      "     \\[\n",
      "     b_1 = \\frac{\\sum{(X - \\bar{X})(Y - \\bar{Y})}}{\\sum{(X - \\bar{X})^2}} \n",
      "     \\]\n",
      "   This determines how much \\(Y\\) is expected to change with a one-unit change in \\(X\\).\n",
      "\n",
      "5. **Calculate the Y-Intercept (b0)**:\n",
      "   ```python\n",
      "   b0 = Y_mean - b1 * X_mean\n",
      "   ```\n",
      "   The y-intercept \\(b_0\\) is determined by inserting the means and the computed slope into the equation:\n",
      "   \\[\n",
      "   b_0 = \\bar{Y} - b_1 \\cdot \\bar{X}\n",
      "   \\]\n",
      "   This gives the expected value of \\(Y\\) when \\(X=0\\).\n",
      "\n",
      "6. **Return the Coefficients**:\n",
      "   ```python\n",
      "   return b0, b1\n",
      "   ```\n",
      "   The function returns two values: the calculated y-intercept \\(b_0\\) and slope \\(b_1\\).\n",
      "\n",
      "### Example Usage\n",
      "At the bottom, there's an example block:\n",
      "\n",
      "```python\n",
      "if __name__ == \"__main__\":\n",
      "    # Sample data\n",
      "    X = [1, 2, 3, 4, 5]\n",
      "    Y = [2, 3, 5, 7, 11]\n",
      "\n",
      "    b0, b1 = linear_regression(X, Y)\n",
      "    print(f\"Y-intercept (b0): {b0}\")\n",
      "    print(f\"Slope (b1): {b1}\")\n",
      "```\n",
      "1. **Sample Data**: Simple lists are defined for `X` and `Y`. You can easily replace them with your own datasets.\n",
      "2. **Function Call**: The `linear_regression` function is called with `X` and `Y` datasets, capturing \\(b_0\\) and \\(b_1\\) for printing.\n",
      "3. **Output**: The results are printed, providing visibility to the y-intercept and slope of the determined best-fit line through the provided data points.\n",
      "\n",
      "### Conclusion\n",
      "This function illustrates a practical technique in regression analysis used to ascertain relationships in data, allowing for applications like prediction tasks, trend analysis, and more. You can easily adapt the `X` and `Y` values to explore how the linear regression model functions with different inputs! Additionally, exploring the coefficients together can offer insights into how strong or reliable these relationships are between your variables.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize the first ChatOpenAI model\n",
    "llm_1 = ChatOpenAI(model_name='gpt-4o-mini', temperature=0.5)\n",
    "\n",
    "# Define the first prompt template\n",
    "prompt_template_1 = PromptTemplate.from_template(\n",
    "    template='You are an experienced scientist and Python programmer. Write a function that implements the concept of {concept}.'\n",
    ")\n",
    "\n",
    "# Create an LLMChain\n",
    "chain_1 = LLMChain(llm=llm_1, prompt=prompt_template_1)\n",
    "\n",
    "# ----------------------- #\n",
    "\n",
    "# Initialize the second ChatOpenAI model (gpt-4o-mini) with specific temperature\n",
    "llm_2 = ChatOpenAI(model_name='gpt-4o-mini', temperature=1.2)\n",
    "\n",
    "# Define the second prompt template\n",
    "prompt_template_2 = PromptTemplate.from_template(\n",
    "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "\n",
    "# Create another LLMChain using the second model and the prompt template\n",
    "chain_2 = LLMChain(llm=llm_2, prompt=prompt_template_2)\n",
    "\n",
    "# ----------------------- #\n",
    "\n",
    "# Combine both chains into a SimpleSequentialChain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain_1, chain_2], verbose=True)\n",
    "\n",
    "# Invoke the overall chain with the concept\n",
    "output = overall_chain.invoke('linear regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Let's go through the provided Python function for **Simple Linear Regression** in detail. Simple linear regression is widely used in statistics and machine learning to assess the relationship between two continuous variables: the dependent variable (often denoted as \\(Y\\)) and the independent variable (denoted as \\(X\\)). \n",
      "\n",
      "### Breakdown of the Function\n",
      "\n",
      "#### Function Definition and Parameters\n",
      "\n",
      "The function `linear_regression(X, Y)` performs simple linear regression on the datasets provided as parameters. \n",
      "\n",
      "**Parameters**:\n",
      "- `X` (array-like): This is the independent variable, or the input data. It represents values upon which predictions about \\(Y\\) (the dependent variable) are made.\n",
      "- `Y` (array-like): This is the dependent variable, or the target endpoint. It denotes outcomes that depend on the values of \\(X\\).\n",
      "\n",
      "#### Core Steps in the Function\n",
      "\n",
      "1. **Import the NumPy Library**: \n",
      "   ```python\n",
      "   import numpy as np\n",
      "   ```\n",
      "   NumPy is always imported for handling numerical operations, particularly for operations involving arrays.\n",
      "\n",
      "   \n",
      "2. **Convert Input Data to Arrays**:\n",
      "   ```python\n",
      "   X = np.array(X)\n",
      "   Y = np.array(Y)\n",
      "   ```\n",
      "   Here, we convert both `X` and `Y` into NumPy arrays. This is important because NumPy provides highly optimized operations and functionalities that allow for efficient calculations on these arrays.\n",
      "\n",
      "3. **Calculate Means of X and Y**:\n",
      "    ```python\n",
      "    X_mean = np.mean(X)\n",
      "    Y_mean = np.mean(Y)\n",
      "    ```\n",
      "   The means (average) of the independent variable `X` and the dependent variable `Y` are computed using NumPy's mean function. \n",
      "\n",
      "   \n",
      "4. **Calculate the Slope (b1)**:\n",
      "   ```python\n",
      "   numerator = np.sum((X - X_mean) * (Y - Y_mean))\n",
      "   denominator = np.sum((X - X_mean) ** 2)\n",
      "   \n",
      "   b1 = numerator / denominator\n",
      "   ```\n",
      "   - The **numerator** computes the summed product of deviations from the mean for both choices, \\( (X-X_{mean}) \\) and \\( (Y-Y_{mean}) \\).\n",
      "   - The **denominator** computes the summed square of the deviations for `X`.\n",
      "   - The slope \\( b_1 \\) is calculated through the formula:\n",
      "     \\[\n",
      "     b_1 = \\frac{\\sum{(X - \\bar{X})(Y - \\bar{Y})}}{\\sum{(X - \\bar{X})^2}} \n",
      "     \\]\n",
      "   This determines how much \\(Y\\) is expected to change with a one-unit change in \\(X\\).\n",
      "\n",
      "5. **Calculate the Y-Intercept (b0)**:\n",
      "   ```python\n",
      "   b0 = Y_mean - b1 * X_mean\n",
      "   ```\n",
      "   The y-intercept \\(b_0\\) is determined by inserting the means and the computed slope into the equation:\n",
      "   \\[\n",
      "   b_0 = \\bar{Y} - b_1 \\cdot \\bar{X}\n",
      "   \\]\n",
      "   This gives the expected value of \\(Y\\) when \\(X=0\\).\n",
      "\n",
      "6. **Return the Coefficients**:\n",
      "   ```python\n",
      "   return b0, b1\n",
      "   ```\n",
      "   The function returns two values: the calculated y-intercept \\(b_0\\) and slope \\(b_1\\).\n",
      "\n",
      "### Example Usage\n",
      "At the bottom, there's an example block:\n",
      "\n",
      "```python\n",
      "if __name__ == \"__main__\":\n",
      "    # Sample data\n",
      "    X = [1, 2, 3, 4, 5]\n",
      "    Y = [2, 3, 5, 7, 11]\n",
      "\n",
      "    b0, b1 = linear_regression(X, Y)\n",
      "    print(f\"Y-intercept (b0): {b0}\")\n",
      "    print(f\"Slope (b1): {b1}\")\n",
      "```\n",
      "1. **Sample Data**: Simple lists are defined for `X` and `Y`. You can easily replace them with your own datasets.\n",
      "2. **Function Call**: The `linear_regression` function is called with `X` and `Y` datasets, capturing \\(b_0\\) and \\(b_1\\) for printing.\n",
      "3. **Output**: The results are printed, providing visibility to the y-intercept and slope of the determined best-fit line through the provided data points.\n",
      "\n",
      "### Conclusion\n",
      "This function illustrates a practical technique in regression analysis used to ascertain relationships in data, allowing for applications like prediction tasks, trend analysis, and more. You can easily adapt the `X` and `Y` values to explore how the linear regression model functions with different inputs! Additionally, exploring the coefficients together can offer insights into how strong or reliable these relationships are between your variables.\n"
     ]
    }
   ],
   "source": [
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `PythonREPL`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes, for complex calculations, rather than have an LLM generate the answer directly, \n",
    "# it can be better to have the LLM generate code to calculate the answer\n",
    "# PythonREPL generally refers to Python's \"Read-Eval-Print Loop,\" \n",
    "# which is an interactive shell used for executing Python code line-by-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[13, 26, 39, 52, 65, 78, 91]\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PythonREPL\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run('print([n for n in range(1, 100) if n % 13 == 0])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Python Agent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo solve this problem, I need to calculate the factorial of 12 and then find the square root of that result. Finally, I will format the output to display it with 4 decimal points.\n",
      "\n",
      "Action: Python_REPL\n",
      "Action Input:\n",
      "```python\n",
      "import math\n",
      "\n",
      "factorial_12 = math.factorial(12)\n",
      "sqrt_factorial_12 = math.sqrt(factorial_12)\n",
      "formatted_result = f\"{sqrt_factorial_12:.4f}\"\n",
      "print(formatted_result)\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m21886.1052\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer. \n",
      "\n",
      "Final Answer: The square root of the factorial of 12, displayed with 4 decimal points, is 21886.1052.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Calculate the square root of the factorial of 12 and display it with 4 decimal points',\n",
       " 'output': 'The square root of the factorial of 12, displayed with 4 decimal points, is 21886.1052.'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the ChatOpenAI model\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "# Create a Python agent using the ChatOpenAI model and a PythonREPLTool (Chain of Thoughts (COT))\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# Invoke the agent\n",
    "prompt = 'Calculate the square root of the factorial of 12 and display it with 4 decimal points'\n",
    "agent_executor.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
