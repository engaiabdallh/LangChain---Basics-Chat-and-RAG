{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "_ = load_dotenv(override=True)\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import tiktoken\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Connect Pinecone`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect pinecone and create an index\n",
    "pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"quickstart\"\n",
    "\n",
    "try:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"cosine\",\n",
    "        spec=pinecone.ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        ) \n",
    "    )\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Get the index itself\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Splitting & Embedding Text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file\n",
    "with open('../assets/churchill_speech.txt') as f:\n",
    "    texts = f.read()\n",
    "\n",
    "\n",
    "# Text Splitter with some params\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# Create Document\n",
    "chunks = text_splitter.create_documents([texts])\n",
    "\n",
    "print(f'Number of Chunks is {len(chunks)}')\n",
    "# An exmaple\n",
    "print(chunks[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the embedding cost\n",
    "enc = tiktoken.encoding_for_model('text-embedding-3-small')\n",
    "total_tokens = sum([len(enc.encode(c.page_content)) for c in chunks])\n",
    "print(f'Total Tokens is: {total_tokens}')\n",
    "print(f'The cost is {total_tokens * 0.02 / 1e6} USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use openai embeddign from langchain\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-small', dimensions=1536)\n",
    "vector_0 = embeddings.embed_query(chunks[0].page_content)\n",
    "vector_0[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Upserting to Pincone`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upserting to Pincone\n",
    "vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check after\n",
    "index.describe_index_stats() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Query`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Where should we fight?'\n",
    "result = vector_store.similarity_search(query=query, k=3)\n",
    "\n",
    "for r in result:\n",
    "    print(r.page_content)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Answering using LLM (RAG)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.2)\n",
    "\n",
    "# Retriever based on simialrity measure\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 4})\n",
    "\n",
    "# Create a RetrievalQA chain using the defined LLM, chain type 'stuff', and retriever\n",
    "# This chain takes a list of documents and formats them all into a prompt, then passes that prompt to an LLM\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example\n",
    "query = 'Answer only from the provided input. Where should we fight?'\n",
    "answer = chain.invoke(query)\n",
    "print(answer['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another example\n",
    "query = 'Answer only from the provided input. Who was the king of Belgium at that time?'\n",
    "answer = chain.invoke(query)\n",
    "print(answer['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another exmaple\n",
    "query = 'Answer only from the provided input. Does French defenses at Sedan?'\n",
    "answer = chain.invoke(query)\n",
    "print(answer['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depi2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
